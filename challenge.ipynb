{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: train_images/748919_61I9XdN6OFL.jpg\n",
      "Downloaded: train_images/916768_71gSRbyXmoL.jpg\n",
      "Downloaded: train_images/459516_61BZ4zrjZXL.jpg\n",
      "Downloaded: train_images/459516_612mrlqiI4L.jpg\n",
      "Downloaded: train_images/731432_617Tl40LOXL.jpg\n",
      "Downloaded: train_images/731432_61QsBSE7jgL.jpg\n",
      "Downloaded: train_images/731432_81xsq6vf2qL.jpg\n",
      "Downloaded: train_images/731432_71DiLRHeZdL.jpg\n",
      "Downloaded: train_images/731432_91Cma3RzseL.jpg\n",
      "Downloaded: train_images/731432_71jBLhmTNlL.jpg\n",
      "Downloaded: train_images/149159_81N73b5khVL.jpg\n",
      "Downloaded: train_images/308856_61oMj2iXOuL.jpg\n",
      "Downloaded: train_images/281678_91LPf6OjV9L.jpg\n",
      "Downloaded: train_images/281678_81fOxWWWKYL.jpg\n",
      "Downloaded: train_images/281678_81dzao1Ob4L.jpg\n",
      "Downloaded: train_images/281678_91-iahVGEDL.jpg\n",
      "Downloaded: train_images/731432_81S2+GnYpTL.jpg\n",
      "Downloaded: train_images/731432_81e2YtCOKvL.jpg\n",
      "Downloaded: train_images/731432_81RNsNEM1EL.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "csv_file = 'train.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "image_dir = 'train_images'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "def download_image(url, group_id):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            image_name = os.path.join(image_dir, f'{group_id}_{os.path.basename(url)}')\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(image_name)\n",
    "            print(f\"Downloaded: {image_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download image from: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {url}: {e}\")\n",
    "for idx, row in data.iterrows():\n",
    "    download_image(row['image_link'], row['group_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "def loadAndPreprocess(img_path, target_size=(224, 224)):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img / 255.0\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_link', 'group_id', 'entity_name', 'entity_value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "\n",
    "image_paths = [os.path.join(image_dir, f'{row[\"group_id\"]}_{os.path.basename(row[\"image_link\"])}') for idx, row in data.iterrows()]\n",
    "images = np.array([loadAndPreprocess(img_path) for img_path in image_paths])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['entity_name_encoded'] = label_encoder.fit_transform(data['entity_name'])\n",
    "\n",
    "import re\n",
    "def extract_numeric_value(value):\n",
    "    match = re.search(r\"[\\d\\.]+\", value)\n",
    "    if match:\n",
    "        return float(match.group(0))\n",
    "    return None\n",
    "\n",
    "data['entity_value'] = data['entity_value'].apply(extract_numeric_value)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "numeric_features = ['entity_value', 'entity_name_encoded', 'group_id']\n",
    "scaled_numeric_data = scaler.fit_transform(data[numeric_features])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scratch model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 800881.4375 - mse: 800881.4375 - val_loss: 21613.3340 - val_mse: 21613.3340\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 796789.4375 - mse: 796789.4375 - val_loss: 18756.7637 - val_mse: 18756.7637\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 782946.6875 - mse: 782946.6875 - val_loss: 14309.9180 - val_mse: 14309.9180\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 758343.2500 - mse: 758343.2500 - val_loss: 8845.1641 - val_mse: 8845.1641\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 716271.0625 - mse: 716271.0625 - val_loss: 7713.8555 - val_mse: 7713.8555\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 654223.6250 - mse: 654223.6250 - val_loss: 28678.3906 - val_mse: 28678.3906\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 576773.7500 - mse: 576773.7500 - val_loss: 125715.4844 - val_mse: 125715.4844\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 522267.2812 - mse: 522267.2812 - val_loss: 375270.0312 - val_mse: 375270.0312\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 590497.7500 - mse: 590497.7500 - val_loss: 361745.0938 - val_mse: 361745.0938\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 582091.6250 - mse: 582091.6250 - val_loss: 245570.4219 - val_mse: 245570.4219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fd7d78d2d90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_input = Input(shape=(224, 224, 3), name='image_input')\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "structured_input = Input(shape=(len(numeric_features),), name='structured_input')\n",
    "y = Dense(64, activation='relu')(structured_input)\n",
    "y = Dense(32, activation='relu')(y)\n",
    "\n",
    "combined = Concatenate()([x, y])\n",
    "\n",
    "z = Dense(64, activation='relu')(combined)\n",
    "z = Dense(32, activation='relu')(z)\n",
    "output = Dense(1, activation='linear')(z) \n",
    "\n",
    "model = Model(inputs=[image_input, structured_input], outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "\n",
    "X_images = np.array(images)\n",
    "X_structured = scaled_numeric_data\n",
    "y = data['entity_value'].values  \n",
    "model.fit([X_images, X_structured], y, epochs=10, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'image_link', 'group_id', 'entity_name'], dtype='object')\n",
      "Downloaded: test_images/156839_110EibNyclL.jpg\n",
      "Downloaded: test_images/792578_11TU2clswzL.jpg\n",
      "Downloaded: test_images/792578_11TU2clswzL.jpg\n",
      "Downloaded: test_images/792578_11TU2clswzL.jpg\n",
      "Downloaded: test_images/792578_11gHj8dhhrL.jpg\n",
      "Downloaded: test_images/792578_11gHj8dhhrL.jpg\n",
      "Downloaded: test_images/792578_11gHj8dhhrL.jpg\n",
      "Downloaded: test_images/156839_11lshEUmCrL.jpg\n",
      "Downloaded: test_images/478357_21+i52HRW4L.jpg\n",
      "Downloaded: test_images/478357_21-LmSmehZL.jpg\n",
      "Downloaded: test_images/953313_213oP6n7jtL.jpg\n",
      "Downloaded: test_images/276611_213wY3gUsmL.jpg\n",
      "Downloaded: test_images/648011_214CLs1oznL.jpg\n",
      "Downloaded: test_images/648011_214CLs1oznL.jpg\n",
      "Downloaded: test_images/648011_214CLs1oznL.jpg\n",
      "Downloaded: test_images/279307_216rjgJHAeL.jpg\n",
      "Downloaded: test_images/569206_2174yonQBtL.jpg\n",
      "Downloaded: test_images/348551_218BCzgKxuL.jpg\n",
      "Downloaded: test_images/348551_218BCzgKxuL.jpg\n"
     ]
    }
   ],
   "source": [
    "test_csv_file = 'test.csv'\n",
    "test_data = pd.read_csv(test_csv_file)\n",
    "test_data.columns = test_data.columns.str.strip()\n",
    "print(test_data.columns)\n",
    "\n",
    "test_dir = 'test_images'\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "def download_image_test(url, group_id):\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            image_name = os.path.join(test_dir, f'{group_id}_{os.path.basename(url)}')\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            image.save(image_name)\n",
    "            print(f\"Downloaded: {image_name}\")\n",
    "        else:\n",
    "            print(f\"Failed to download image from: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {url}: {e}\")\n",
    "\n",
    "\n",
    "for idx, row in test_data.iterrows():\n",
    "    download_image_test(row['image_link'], row['group_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[0;34m(values, uniques)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:165\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([table[v] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'height'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_path \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_link\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m test_data\u001b[38;5;241m.\u001b[39miterrows()]\n\u001b[1;32m      2\u001b[0m test_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([loadAndPreprocess(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m test_path])\n\u001b[0;32m----> 4\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_name_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mtransform(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m test_scaled_numeric_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(test_data[numeric_features])\n\u001b[1;32m      8\u001b[0m test_X_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(test_images)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: y contains previously unseen labels: 'height'"
     ]
    }
   ],
   "source": [
    "test_path = [os.path.join(test_dir, f'{row[\"group_id\"]}_{os.path.basename(row[\"image_link\"])}') for idx, row in test_data.iterrows()]\n",
    "test_images = np.array([loadAndPreprocess(img_path) for img_path in test_path])\n",
    "\n",
    "test_data['entity_name_encoded'] = label_encoder.transform(test_data['entity_name'])\n",
    "\n",
    "test_scaled_numeric_data = scaler.transform(test_data[numeric_features])\n",
    "\n",
    "test_X_images = np.array(test_images)\n",
    "test_X_structured = test_scaled_numeric_data\n",
    "\n",
    "test_predictions = model.predict([test_X_images, test_X_structured])\n",
    "\n",
    "print(\"Predicted values for test data:\")\n",
    "for i in range(10):\n",
    "    print(f\"Group ID: {test_data['group_id'].iloc[i]}, Predicted Value: {test_predictions[i][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tesseract and SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {image_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def perform_ner(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
